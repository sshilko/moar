---
layout: post
title: Trying out serverless in 2020
---

#### Part I - Hype 

2018 and 2019 is when [Kubernetes](https://www.cncf.io/blog/2018/03/06/kubernetes-first-cncf-project-graduate/) and [Serverless](https://serverless.com/blog/) became mainstream.

- [Kubernetes](https://kubernetes.io/blog/) graduated from CNCF in 2018 
- [Kubeless](The Kubernetes Native Serverless Framework) FAAS on Kubernetes
- [AWS Lambda now supports Java 11](https://aws.amazon.com/about-aws/whats-new/2019/11/aws-lambda-supports-java-11/)
- AWS API Gateway v2 for HTTP (replacement of ALB+Lambda combo)
- AWS Lambda Destinations and Asynchronous Invocation Improvements
- Announcing Serverless CI/CD (2020)
- AWS Native [SAM](https://aws.amazon.com/serverless/sam/) alternative to serverless.com
- [AWS Lambda Now Supports Custom Runtimes](https://aws.amazon.com/about-aws/whats-new/2018/11/aws-lambda-now-supports-custom-runtimes-and-layers/)
- [PHP goes serverless with Laravel Vapor in 2019](https://vapor.laravel.com/)
- [The AWS Serverless Application Repository](https://aws.amazon.com/serverless/serverlessrepo/)
- [AWS App Mesh Service Discovery](https://aws.amazon.com/about-aws/whats-new/2019/06/aws-app-mesh-service-discovery-with-aws-cloud-map-generally-available/)
- [CNCF Cloud Native Interactive Landscape](https://landscape.cncf.io/format=serverless)
- [AWS Database Migration Service got more mature](https://docs.aws.amazon.com/dms/index.html)
- [Go](https://golang.org/) released modules support finally in 1.13
- AOT JVM based micro-frameworks for Serverless started to gain strength, i.e. [Micronaut](micronaut.io) or [Quarkus](quarkus.io)
- [Improved VPC networking for AWS Lambda functions](https://aws.amazon.com/blogs/compute/announcing-improved-vpc-networking-for-aws-lambda-functions/)
...

We wanted to try and finally in summer 2019 we decided to try out microservices.

#### Part II - Legacy

We have our backend in PHP7.3 and every year we migrate to new version of PHP, but that only means we clean-up our codebase
to be compatible with latest releases, we dont have time/luxury to rewrite everything every year.

* Backend is >5 years SOA backend app that exposes API.
* Everything runs on AWS inside Docker.
* We follow KISS and SOA, we did few "internal services" that communicate over JSON-RPC API
* Codebase is pretty stable <0.1% errors
* App is in Production for years, cant afford downtime

#### Part III - Dream

![serverless2019](/images/serverless2019.jpg)

Somewhere in November 2019 we finally decided on the JIRA ticked and put research ticket into sprint.

TLDR

- Replace one PHP service 
- Scale to 0 (reduce costs)
- Use serverless (no servers please)
- Expose as REST API
- Expose nice autogenerated documentation
- Try out new language (Java, Kotlin, Go, Python ... [PHP runs in Kubeless](https://github.com/kubeless/kubeless/tree/master/examples/php) btw.)
- Better monitoring, more security, develope common standard/stack for future microservices
- Standard (no UI) console-only/cli deployment, turnkey solution

The service involved
- AWS S3
- AWS RDS

and we decided to swap it to
- AWS S3
- AWS DynamoDB

to be completely "Serverless"

#### Part VI - Beginning

- As we already use AWS, we decided to go with AWS Lambda.
- Looking at multiple benchmarks/cold-start of runtimes, we ended up with Golang/JVM options, and decided for JVM
- Among JVM we found out [Micronaut framework](https://guides.micronaut.io/micronaut-function-aws-lambda/guide/index.html) to be really similar with SpringBoot, and otherwise standard AWS SDK for Java
- We used JVM8 because AWSSDK2 was not yet stable/released by the time.
- We used [Serverless.com](https://serverless.com/) framework as recommended by other frond-end team that had experience with it,
also [AWS SAM](https://aws.amazon.com/serverless/sam/) lacked some of the features we needed, like Lambda+ALB setup out of the box.

- PHP service will be replaced with really similar Rest API running AWS Lambda HTTP endpoint
- RDS database will be replaced with DynamoDB serverless database
- Micronaut supports generating Swagger documentation out of the box
- We used Kotlin with Micronaut to spice things up and bring more challenge
- All monitoring is provided by AWS CloudWatch and is out-of-the-box
- Service scales "ondemand" from 0 to "alot", there are /keaplive endpoint connected to ALB healthckeck to prevent cold-start
- Serverless.com framework only needs AWS KEY/Secret to deploy, whole build of Kotlin/Java is done inside MultiStage docker files of 
standard aws/java corretto images and does not require anything except docker installed.
- Whole code and everything needed for deployment is hosted in separate Github repository

#### Part V - Reality (spoilers)

- Kotlin/Micronaut app ended up being 23.5MB Jar file and use 230MB memory with average 8ms response time
- Kotlin lacked alot of documentation for serverless domain
- Should have written Kotlin tests from the beginning
- [AWS DMS Migration](https://aws.amazon.com/blogs/database/debugging-your-aws-dms-migrations-what-to-do-when-things-go-wrong-part-3/) (RDS->Dynamodb) took us 2 weeks !!! to figure out with try/fail,
there is very very little on debugging DMS migrations, thigs you will not encounter on small/test datasets but that WILL happen on big production migrations
* How to choose DMS Instance size ??? (TLDR just pick the biggest instance c4.4xlarge)
* How to choose DMS task configuration ??? (TLDR defaults wont work)
* Why DMS is so slow ??? (TLDR defaults suck)
* DMS Configuration is really specific to source and destination (Oracle->PostgreSQL, MySQL->DynamoDB, ...) every combination has its own options,
that you can only fine-tune by editing JSON task configuration (no UI, very little help)

If you migrate to DynamoDB, we got some experince =)

- Migration and Migration+Replication are NOT the same experince, latter has much more hidden issues
- Not more than 7000~8000 capacity units writes on DynamoDB... or it will fail, we had to fall back to ~4000 capacity for stable migration
- pick biggest DMS instance for migration, CPU is the bottleneck
- This happens `Last Error Task 'MYJHGWWJB54WQBZ76XXXXXXX' was suspended due to 6 successive unexpected failures Stop Reason FATAL_ERROR Error Level FATAL` and you wont get any other logs
- Try tuning `unloadTimeout`, `ForceUnloadTimeout` but in our case that didnt help, something somewhere times-out
- You can use `root` user for source, but for MySQL you only need read-only access with `GRANT REPLICATION CLIENT` permissions
```
    REPLICATION CLIENT – This privilege is required for change data capture (CDC) tasks only. 
    REPLICATION SLAVE  – This privilege is required for change data capture (CDC) tasks only. 
    SUPER              – This privilege is required only in MySQL versions before 5.6.6.
```
- Vodoo magic needed for RDS binlogs for long DMS migrations 
```
call mysql.rds_show_configuration;
call mysql.rds_set_configuration('binlog retention hours', 24);
```
- Recommended SQL->DynamoDB settings for Task, this is mostly black magic, but there is very little documentation on it
 
```
TargetMetadata.ParallelLoadThreads: 24
TargetMetadata.BatchApplyEnabled: false
FullLoadSettings.TransactionConsistencyTimeout: 300
FullLoadSettings.CommitRate: 20000
StreamBufferSettings.StreamBufferCount: 12
StreamBufferSettings.StreamBufferSizeInMB: 40
StreamBufferSettings.CtrlStreamBufferSizeInMB: 8
ChangeProcessingTuning.MinTransactionSize: 1000
ChangeProcessingTuning.CommitTimeout: 5
ChangeProcessingTuning.MemoryLimitTotal: 1024
ChangeProcessingTuning.MemoryKeepTime: 60
ChangeProcessingTuning.StatementCacheSize: 50
```


#### Part VI - tres meses despues

Overall API response times during migration from PHP+SQL solution to AWS/Serverless + DynamoDB

![2020_Clients_SLA](/images/serverless2020/2020_Clients_SLA.png)

API response 50/95/99% 

![2020_Clients_SLA_P](/images/serverless2020/2020_Clients_SLA_P.png)

Microservice response - timings measured on *client side* (no percentiles unfortunatelly, NewRelic)

![2020_AWSLambda_MicronautResponseTimes](/images/serverless2020/2020_AWSLambda_MicronautResponseTimes.png)

Microservice response - timings measured on *Lambda side* (AWS CloudWatch)

![2020_AWSLambda_MicronautStats](/images/serverless2020/2020_AWSLambda_MicronautStats.png)

#### Summary

![2020_club](/images/serverless2020/2020_club.jpg)

We will continue learning and trying out new technologies, we are happy to see the solution works stable and overall
concept work. Performance was never our priority, but we always tried to use the latest/best tools we could, but seems
like bottlenecks are not in our environment (language, framework, runtime) but rather on the PAAS side of AWS (S3)

Achievements unlocked:

- removed memory hungry processing out into lambda and freed more memory inside docker for more PHP workers
- reduced the 95% and 99% response times, and removed long S3 calls into AWS Lambda where they dont 
consume limited EC2/Docker resources (memory!)
- deprecated legacy PHP codebase, cleaned up SQL database of unnecessary data (non relational)
- new microservice can be improved/deployed/maintained completely separate of main codebase
- we learned many new things on practice: 
  - new language - Kotlin & Java
  - new framework - Micronaut, Micronaut Test, AWS Java SDK
  - new CI/CD framework - AWS SAM, Serverless.com
  - new runtime - AWS Lambda
  - new database - AWS DynamoDB
  - zero downtime migration of production/big databases from SQL to DynamoDB

#### Shout-Out

Carolina A. for pressing the production deployment button during peak load times on weekday.

![Caro](/images/serverless2020/2020_shotout.jpg)

#### Update 26 Feb 2020
   * Initial release